# Awesome Action Quality Assessment
Action Quality Assessment aims at evaluating and quantifying the overall performance or proficiency of human actions based on the analysis of video or motion data.

In this reprository, interetsting papers in AQA are collected to show the development of the AQA community. Moreover, some papers about similar tasks and datasets are listed.

## Main Road
### Survey
- A Decade of Action Quality Assessment: Largest Systematic Survey of Trends, Challenges, and Future Directions **(ArXiv 2025)** [[Paper]](https://arxiv.org/abs/2502.02817) [[Project]](https://haoyin116.github.io/Survey_of_AQA/)
- A Comprehensive Survey of Action Quality Assessment: Method and Benchmark **(ArXiv 2024)** [[Paper]](https://arxiv.org/abs/2412.11149) [[Project]](https://zhoukanglei.github.io/AQA-Survey/)
- Vision-based human action quality assessment: A systematic review **(2024)**
- A Survey of Video-based Action Quality Assessment **(INSAI 2022)**  [[Paper]](https://arxiv.org/pdf/2204.09271v1.pdf)

### 2025 
- From Beats to Scores: A Multi-Modal Framework for Comprehensive Figure Skating Assessment **(CVPRW 2025)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/papers/Wang_From_Beats_to_Scores_A_Multi-Modal_Framework_for_Comprehensive_Figure_CVPRW_2025_paper.pdf) [[Code]](https://github.com/ycwfs/Figure-Skating-Quality-Assessment)
- ExAct: A Video-Language Benchmark for Expert Action Analysis **(ArXiv 2025)** [[Paper]](https://arxiv.org/pdf/2506.06277) [[Project]](https://texaser.github.io/exact_project_page/) [[Code]](https://github.com/Texaser/Exact)
- FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment **(ArXiv 2025)** [[Paper]](https://arxiv.org/pdf/2506.03198.pdf) [[Code]](https://github.com/HaoYin116/FLEX)
- PHI: Bridging Domain Shift in Long-Term Action Quality Assessment via Progressive Hierarchical Instruction **(TIP 2025)** [[Paper]](https://arxiv.org/abs/2505.19972) [[Code]](https://github.com/ZhouKanglei/PHI_AQA)
- Language-Guided Audio-Visual Learning for Long-Term Sports Assessment **(CVPR 2025)**
- BASKET üèÄ : A Large-Scale Video Dataset for Fine-Grained Skill Estimation **(CVPR 2025)** [[Paper]](https://arxiv.org/abs/2503.20781) [[Project]](https://sites.google.com/cs.unc.edu/basket) [[Code]](https://github.com/yulupan00/BASKET/tree/main)
- Pose-Guided Transformer for Fine-Grained Action Quality Assessment **(TCSVT 2025)** [[Paper]](https://ieeexplore.ieee.org/abstract/document/10902635)
- Adaptive Spatiotemporal Graph Transformer Network for Action Quality Assessment **(TCSVT 2025)** [[Paper]](https://ieeexplore.ieee.org/abstract/document/10884538) [[Code]](https://github.com/jiangliu5/ASGTN_AQA)
- Action Quality Assessment via Hierarchical Pose-guided Multi-stage Contrastive Regression **(ArXiv 2025)** [[Paper]](https://arxiv.org/abs/2501.03674) [[Project]](https://github.com/Lumos0507/HP-MCoRe)

### 2024
- Visual-semantic Alignment Temporal Parsing for Action Quality Assessment **(TCSVT 2024)** [[Paper]](https://ieeexplore.ieee.org/document/10737230)
- Self-supervised subaction parsing network for semi-supervised action quality assessment **(TIP 2024)** [[Paper]](https://ieeexplore.ieee.org/abstract/document/10706814)
- LucidAction: A Hierarchical and Multi-model Dataset for Comprehensive Action Quality Assessment **(NeurIPS 2024)**
- Rhythmer: Ranking-based Skill Assessment with Rhythm-aware Transformer **(TCSVT 2024)** [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10679980)
- Interpretable Long-term Action Quality Assessment **(BMVC 2024)** [[Paper]](https://arxiv.org/abs/2408.11687) [[Code]](https://github.com/dx199771/Interpretability-AQA)
- Vision-Language Action Knowledge Learning for Semantic-Aware Action Quality Assessment **(ECCV 2024)** [[Paper]](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05909.pdf)
- RICA2: Rubric-Informed, Calibrated Assessment of Actions **(ECCV 2024)** [[Paper]](https://arxiv.org/abs/2408.02138) [[Project]](https://abrarmajeedi.github.io/rica2_aqa/) [[Code]](https://github.com/abrarmajeedi/rica2_aqa)
- MAGR: Manifold-Aligned Graph Regularization for Continual Action Quality Assessment **(ECCV 2024)** [[Paper]](arxiv.org/abs/2403.04398) [[Code]](https://github.com/ZhouKanglei/MAGR_CAQA)
- Semi-Supervised Teacher-Reference-Student Architecture for Action Quality Assessment **(ECCV 2024)** [[Paper]](https://arxiv.org/abs/2407.19675)
- Procedure-Aware Action Quality Assessment: Datasets and Performance Evaluation **(IJCV 2024)** [[Paper]](https://link.springer.com/article/10.1007/s11263-024-02146-z) [[Code]](https://github.com/xujinglin/FineDiving)
- Continual Action Assessment via Task-Consistent Score-Discriminative Feature Distribution Modeling **(TCSVT 2024)** [[Paper]](https://arxiv.org/abs/2309.17105) [[Code]](https://github.com/iSEE-Laboratory/Continual-AQA)
- CoFInAl: Enhancing Action Quality Assessment with Coarse-to-Fine Instruction Alignment **(IJCAI 2024)** [[Paper]](https://arxiv.org/pdf/2404.13999.pdf) [[Code]](https://github.com/ZhouKanglei/CoFInAl_AQA)
- FineParser: A Fine-grained Spatio-temporal Action Parser for Human-centric Action Quality Assessment **(CVPR 2024 Oral)** [[Paper]](https://arxiv.org/pdf/2405.06887#pdfjs.action=download) [[Code]](https://github.com/PKU-ICST-MIPL/FineParser_CVPR2024)
- Narrative Action Evaluation with Prompt-Guided Multimodal Interaction **(CVPR 2024)** [[Paper]](https://arxiv.org/abs/2404.14471) [[Code]](https://github.com/shiyi-zh0408/NAE_CVPR2024)
- CPR-Coach: Recognizing Composite Error Actions based on Single-class Training **(CVPR 2024)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_CPR-Coach_Recognizing_Composite_Error_Actions_based_on_Single-class_Training_CVPR_2024_paper.pdf) [[Code]](https://github.com/Shunli-Wang/CPR-Coach)
- Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment **(CVPRW 2024)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Okamoto_Hierarchical_NeuroSymbolic_Approach_for_Comprehensive_and_Explainable_Action_Quality_Assessment_CVPRW_2024_paper.html) [[Code]](https://github.com/laurenok24/NSAQA)
- Multimodal Action Quality Assessment **(TIP 2024)** [[Paper]](https://arxiv.org/abs/2402.09444) [[Code]](https://github.com/qinghuannn/PAMFN)

### 2023
- Fine-Grained Spatio-Temporal Parsing Network for Action Quality Assessment **(TIP 2023)** [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10317826)
- PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment **(WACV 2023 Oral)** [[Paper]](https://arxiv.org/pdf/2311.07603.pdf) [[Code]](https://github.com/Plrbear/PECoP)
- Learning Semantics-Guided Representations for Scoring Figure Skating **(TMM 2023)** [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10301591)
- A Figure Skating Jumping Dataset for Replay-Guided Action Quality Assessment **(ACM-MM 2023)** [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3581783.3613774)
- Localization-assisted Uncertainty Score Disentanglement Network for Action Quality Assessment **(ACM-MM 2023)** [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3581783.3613795) [[Code]](https://github.com/yanliji/FineFS-dataset)
- SEDSkill: Surgical Events Driven Method for Skill Assessment from Thoracoscopic Surgical Videos **(MICCAI 2023)**[[Paper]](https://link.springer.com/chapter/10.1007/978-3-031-43996-4_4) [[Code]](https://github.com/xmed-lab/SEDSkill)
- LOGO: A Long-Form Video Dataset for Group Action Quality Assessment **(CVPR 2023)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_LOGO_A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment_CVPR_2023_paper.pdf) [[Code]](https://github.com/shiyi-zh0408/LOGO) [[Citations]](https://scholar.google.com/scholar?cites=9879603589772082553&as_sdt=2005&sciodt=0,5&hl=en)
- Herarchical Graph Convolutional Networks for Action Quality Assessment **(TCSVT 2023)** [[Paper]](https://dro.dur.ac.uk/38628/1/38628.pdf) [[Code]](https://github.com/ZhouKanglei/HGCN_AQA)
- Adaptive Stage-Aware Assessment Skill Transfer for Skill Determination **(TMM 2023)** [[Paper]](https://ieeexplore.ieee.org/abstract/document/10180083)
- IRIS: Interpretable Rubric-Informed Segmentation for Action Quality Assessment **(ACM-IUI 2023)** [[Paper]](https://arxiv.org/pdf/2303.09097.pdf)
- Skating-Mixer: Multimodal MLP for Scoring Figure Skating **(AAAI 2023)** [[Paper]](https://arxiv.org/pdf/2203.03990.pdf)

### 2022
- Automatic Modelling for Interactive Action Assessment **(IJCV 2022)** [[Paper]](https://link.springer.com/article/10.1007/s11263-022-01695-5) [[Citations]](https://scholar.google.com/scholar?cites=2639298877441859541&as_sdt=2005&sciodt=0,5&hl=en)
- 3D-Yoga: A 3D Yoga Dataset for Visual-based Hierarchical Sports Action Analysis **(ACCV 2022)** [[Paper]](https://openaccess.thecvf.com/content/ACCV2022/papers/Li_3D-Yoga_A_3D_Yoga_Dataset_for_Visual-based_Hierarchical_Sports_Action_ACCV_2022_paper.pdf)
- Hand Hygiene Assessment via Joint Step Segmentation and Key Action Scorer **(ArXiv 2022)**  [[Paper]](https://arxiv.org/pdf/2209.12221)
- Action Quality Assessment with Temporal Parsing Transformer **(ECCV 2022)**  [[Paper]](https://arxiv.org/pdf/2207.09270)  [[Code]](https://github.com/baiyang4/aqa_tpt) [[Citations]](https://scholar.google.com/scholar?cites=3265520373943129836&as_sdt=2005&sciodt=0,5&hl=en)
- Pairwise Contrastive Learning Network for Action Quality Assessment **(ECCV 2022)** [[Paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640450.pdf) [[Code]](https://github.com/hqu-cst-mmc/PCLN)
- FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality Assessment **(CVPR 2022 Oral)** [[paper]](https://arxiv.org/pdf/2204.03646.pdf) [[Code]](https://github.com/xujinglin/FineDiving) [[Citations]](https://scholar.google.com/scholar?cites=5125588138588766817&as_sdt=2005&sciodt=0,5&hl=en)
- Likert Scoring with Grade Decoupling for Long-term Action Assessment **(CVPR 2022)**[[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Likert_Scoring_With_Grade_Decoupling_for_Long-Term_Action_Assessment_CVPR_2022_paper.pdf) [[Code]](https://github.com/xuangch/CVPR22_GDLT)[[Citations]](https://scholar.google.com/scholar?cites=7216274328792820037&as_sdt=2005&sciodt=0,5&hl=en)
- Semi-Supervised Action Quality Assessment With Self-Supervised Segment Feature Recovery **(TCSVT 2022)**[[Paper]](https://ieeexplore.ieee.org/abstract/document/9682696)
- Should I take a walk? Estimating Energy Expenditure from Video Data **(CVPRW 2022)**[[Paper]](https://openaccess.thecvf.com/content/CVPR2022W/CVPM/papers/Peng_Should_I_Take_a_Walk_Estimating_Energy_Expenditure_From_Video_CVPRW_2022_paper.pdf) [[Code]](https://github.com/KPeng9510/Vid2Burn)
- Domain Knowledge-Informed Self-Supervised Representations for Workout Form Assessment **(ECCV 2022)** [[Paper]](https://arxiv.org/pdf/2202.14019) [[Code]](https://github.com/ParitoshParmar/Fitness-AQA)[[Citations]](https://scholar.google.com/scholar?cites=1771967292738028463&as_sdt=2005&sciodt=0,5&hl=en)
- Uncertainty-Driven Action Quality Assessment **(ArXiv 2022)** [[Paper]](https://arxiv.org/pdf/2207.14513.pdf)
- Surgical Skill Assessment via Video Semantic Aggregation **(MICCAI 2022)** [[Paper]](https://arxiv.org/pdf/2208.02611)[[Code]](https://github.com/shinkyo0513/Surgical-Skill-Assessment-via-Video-Semantic-Aggregation)

### 2021
- Adaptive Action Assessment **(TPAMI 2021)** [[Paper]](https://ieeexplore.ieee.org/abstract/document/9609694)
- EAGLE-Eye: Extreme-pose Action Grader using detaiL bird‚Äôs-Eye view **(WACV 2021)** [[paper]](https://openaccess.thecvf.com/content/WACV2021/papers/Nekoui_EAGLE-Eye_Extreme-Pose_Action_Grader_Using_Detail_Birds-Eye_View_WACV_2021_paper.pdf) [[Code]](https://github.com/MahdiNek/EAGLE-Eye)
- Auto-Encoding Score Distribution Regression for Action Quality Assessmentt **(ArXiv 2021)**[[Paper]](https://arxiv.org/abs/2111.11029)
- TSA-Net: Tube Self-Attention Network for Action Quality Assessment **(ACM-MM 2021 Oral)** [[Paper]](https://arxiv.org/pdf/2201.03746) [[Code]](https://github.com/Shunli-Wang/TSA-Net)
- AIFit: Automatic 3D Human-Interpretable Feedback Models for Fitness Training **(CVPR 2021)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Fieraru_AIFit_Automatic_3D_Human-Interpretable_Feedback_Models_for_Fitness_Training_CVPR_2021_paper.html) [[Project]](https://fit3d.imar.ro/home) [[Citations]](https://scholar.google.com/scholar?cites=1608896424763202625&as_sdt=2005&sciodt=0,5&hl=en)
- Towards Unified Surgical Skill Assessment **(CVPR 2021)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Towards_Unified_Surgical_Skill_Assessment_CVPR_2021_paper.pdf) [[Code]](https://github.com/Finspire13/Towards-Unified-Surgical-Skill-Assessment)
- Group-aware Contrastive Regression for Action Quality Assessment **(ICCV 2021)** [[Paper]](http://openaccess.thecvf.com//content/ICCV2021/papers/Yu_Group-Aware_Contrastive_Regression_for_Action_Quality_Assessment_ICCV_2021_paper.pdf) [[Code]](https://github.com/yuxumin/CoRe)
- Will You Ever Become Popular? Learning to Predict Virality of Dance Clips **(TMC 2021)** [[Paper]](https://arxiv.org/pdf/2111.03819v1.pdf)
- Piano Skill Assessment **(ArXiv 2021)** [[Paper]](https://arxiv.org/pdf/2101.04884)


### 2020
- An Asymmetric Modeling for Action Assessment **(ECCV 2020)** [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750222.pdf)
- FALCONS: FAst Learner-grader for CONtorted poses in Sports **(CVPRW 2020)** [[Paper]](http://openaccess.thecvf.com/content_CVPRW_2020/papers/w53/Nekoui_FALCONS_FAst_Learner-Grader_for_CONtorted_Poses_in_Sports_CVPRW_2020_paper.pdf)
- Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos **(ACM-MM 2020)** [[Paper]](https://arxiv.org/pdf/2008.05977v1.pdf) [[Code]](https://github.com/lingan1996/ACTION-NET)
- Uncertainty-aware Score Distribution Learning for Action Quality Assessment **(CVPR 2020)** [[Paper]](https://arxiv.org/pdf/2006.07665v1.pdf) [[Code]](https://github.com/nzl-thu/musdl)

### 2019
- Action Assessment by Joint Relation Graph **(ICCV 2019 Oral)** [[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Pan_Action_Assessment_by_Joint_Relation_Graphs_ICCV_2019_paper.pdf)
- Manipulation-skill Assessment from Videos with Spatial Attention Network **(ICCVW 2019)** [[Paper]](http://openaccess.thecvf.com/content_ICCVW_2019/papers/EPIC/Li_Manipulation-Skill_Assessment_from_Videos_with_Spatial_Attention_Network_ICCVW_2019_paper.pdf)
- The Pros and Cons: Rank-aware Temporal Attention for Skill Determination in Long Videos **(CVPR 2019)** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Doughty_The_Pros_and_Cons_Rank-Aware_Temporal_Attention_for_Skill_Determination_CVPR_2019_paper.pdf) [[Code]](https://github.com/hazeld/rank-aware-attention-network)
- What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment **(CVPR 2019)** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Parmar_What_and_How_Well_You_Performed_A_Multitask_Learning_Approach_CVPR_2019_paper.pdf) [[Code]](https://github.com/ParitoshParmar/MTL-AQA)

### 2018
- Who‚Äôs Better? Who‚Äôs Best? Pairwise Deep Ranking for Skill Determination **(CVPR 2018)** [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Doughty_Whos_Better_Whos_CVPR_2018_paper.pdf)
- S3D: Stacking Segmental P3D for Action Quality Assessment **(ICIP 2018)** [[Paper]](https://ieeexplore.ieee.org/abstract/document/8451364)
- End-To-End Learning for Action Quality Assessment **(PCM 2018)** [[Paper]](https://link.springer.com/chapter/10.1007/978-3-030-00767-6_12)

### 2017
- Am I a Baller? Basketball Performance Assessment from First-Person Videos **(ICCV 2017)** [[Paper]](https://openaccess.thecvf.com/content_ICCV_2017/papers/Bertasius_Am_I_a_ICCV_2017_paper.pdf)
 
## Similar tasks and Potential Datasets
### Datasets
- Viewpoint Rosetta Stone: Unlocking Unpaired Ego-Exo Videos for View-invariant Representation Learning **(CVPR 2025)** [[project]](https://vision.cs.utexas.edu/projects/ViewpointRosetta/)
- Live Fitness Coaching as a Testbed for Situated Interaction **(ArXiv 2024)** [[Paper]](https://arxiv.org/abs/2407.08101) [[Project]](https://developer.qualcomm.com/software/ai-datasets/qevd)
- EgoExo-Fitness: Towards Egocentric and Exocentric Full-Body Action Understanding **(ECCV 2024)** [[Paper]](https://arxiv.org/abs/2406.08877) [[Code]](https://github.com/iSEE-Laboratory/EgoExo-Fitness/tree/main)
- Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives **(CVPR 2024)** [[Project]](https://ego-exo4d-data.org/#people) [[Paper]](https://ego-exo4d-data.org/paper/ego-exo4d.pdf) [[Citations]](https://scholar.google.com/scholar?cites=6807725739327920288&as_sdt=2005&sciodt=0,5&hl=en) [[Code]](https://github.com/EGO4D?tab=repositories)
- EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World **(CVPR 2024)** [[Paper]](https://arxiv.org/pdf/2403.16182.pdf) [[Code]](https://github.com/OpenGVLab/EgoExoLearn/)
- FLAG3D: A 3D Fitness Activity Dataset with Language Instruction **(CVPR 2023)** [[Project]](https://andytang15.github.io/FLAG3D/) [[Paper]](https://arxiv.org/abs/2212.04638) [[Citations]](https://scholar.google.com/scholar?cites=13191913368764386186&as_sdt=2005&sciodt=0,5&hl=en)
- Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities **(CVPR 2022)** [[Project]](https://assembly-101.github.io) [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf) [[Code]](https://github.com/assembly-101?tab=repositories) [[Citations]](https://scholar.google.com/scholar?cites=16985062727042180828&as_sdt=2005&sciodt=0,5&hl=en)
- 

### Narrative Action Assessment
- Vid2Coach: Transforming How-To Videos into Task Assistants **(CVPRW 2025)**
- TechCoach: Towards Technical Keypoint-Aware Descriptive Action Coaching **(ArXiv 2024)** [[Paper]](https://arxiv.org/abs/2411.17130)
- ExpertAF: Expert Actionable Feedback from Video **(CVPR 2025)** [[Paper]](https://arxiv.org/abs/2408.00672) [[Project]](https://vision.cs.utexas.edu/projects/ExpertAF/)
- Narrative Action Evaluation with Prompt-Guided Multimodal Interaction **(CVPR 2024)** [[Paper]](https://arxiv.org/abs/2404.14471) [[Code]](https://github.com/shiyi-zh0408/NAE_CVPR2024)
- Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision **(ArXiv 2024)** [[Paper]](https://arxiv.org/abs/2407.06189) [[Project]](https://orrzohar.github.io/projects/video-star/) [[Code]](https://github.com/orrzohar/Video-STaR)


### Mistake Detection
- Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos **(NeurIPS 2024)** [[Paper]](https://arxiv.org/abs/2406.01486) [[Code]](https://github.com/fpv-iplab/Differentiable-Task-Graph-Learning)
- Find the Assembly Mistakes: Error Segmentation for Industrial Applications **(ECCVW 2024)** [[Project]](https://timschoonbeek.github.io/error_seg) [[Code]](https://github.com/Dan-Leh/find-my-assembly-mistakes)
- Error Detection in Egocentric Procedural Task Videos **(CVPR 2024)** [[Paper]](https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Error_Detection_in_Egocentric_Procedural_Task_Videos_CVPR_2024_paper.html) [[Code]](https://github.com/robert80203/EgoPER_official)
- PREGO: online mistake detection in PRocedural EGOcentric videos **(CVPR 2024)** [[Paper]](https://arxiv.org/abs/2404.01933) [[Code]](https://github.com/aleflabo/PREGO)
- IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting **(WACV 2023)** [[Paper]](https://arxiv.org/pdf/2310.17323.pdf) [[Code]](https://github.com/TimSchoonbeek/IndustReal)
- Weakly-Supervised Action Segmentation and Unseen Error Detection in Anomalous Instructional Videos **(ICCV 2023)** [[Project]](https://usa.honda-ri.com/ata) [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.html) 
- HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World **(ICCV 2023)** [[Project]](https://holoassist.github.io) [[Paper]](http://openaccess.thecvf.com/content/ICCV2023/html/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.html) [[Citations]](https://scholar.google.com/scholar?cites=1935067381543829055&as_sdt=2005&sciodt=0,5&hl=en) [[Citations]](https://scholar.google.com/scholar?cites=1935067381543829055&as_sdt=2005&sciodt=0,5&hl=en)
- CaptainCook4D: A dataset for understanding errors in procedural activities **(ICMLW 2023)** [[Project]](https://captaincook4d.github.io/captain-cook/) [[Paper]](https://arxiv.org/abs/2312.14556) [[Code]](https://github.com/CaptainCook4D)
- Every Mistake Counts in Assembly **(ArXiv 2023)** [[Paper]](https://arxiv.org/abs/2307.16453) [[Code]](https://github.com/assembly-101/assembly101-mistake-detection)

### Video Action Differencing
- Video Action Differencing **(ICLR 2025)** [[Project]](https://jmhb0.github.io/viddiff_web/) [[Code]](https://github.com/jmhb0/VidDiff) [[Paper]](https://openreview.net/pdf?id=3bcN6xlO6f)

### Adverb Recognition
- Learning Action Changes by Measuring Verb-Adverb Textual Relationships **(CVPR 2023)** [[Paper]](https://arxiv.org/pdf/2303.15086.pdf) [[Code]](https://github.com/dmoltisanti/air-cvpr23) [[Citations]](https://scholar.google.com/scholar?cites=50297929267165770&as_sdt=2005&sciodt=0,5&hl=en)








